{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Web Index\n",
    "## Junior Data Engineer Task\n",
    "### Matthew Bibby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This report aims to convey how the assigned problem was undertaken, as well as the thought processes behind the decisions made, and any problems that were faced.\n",
    "The problem involved a number of steps including; learning about how and why to weight respondents in a population, cleaning a dataset which is going to be worked on, and fixing a bug in a factor weighting function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Setting up the CSV File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing the Data\n",
    "The first step was to describe the data, this was achieved by using some pandas functions. The .shape function provides some basic information on the data, such as the number of records and columns containted within the data. Most of the data was low integers such as 1 or 0, with some data being slightly higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 100200\n",
      "Number of columns: 2500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read in input file\n",
    "    df = pd.read_csv('input_data.csv', index_col=0)\n",
    "    \n",
    "    # Get the shape of the input data\n",
    "    shape = df.shape\n",
    "\n",
    "    print(\"Number of records: \" + str(shape[0]))\n",
    "    print(\"Number of columns: \" + str(shape[1]))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicate Indexes\n",
    "This step involved removing duplicate indexes from the data. The pandas library was used here, with the .duplicated function being used to remove the duplicates. The results below show that there are no longer any duplicated indexes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Indexes were found to be duplicates\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Read in input file\n",
    "    df = pd.read_csv('input_data.csv', index_col=0)\n",
    "    \n",
    "    # Remove duplicate indexes, keep the first instance\n",
    "    dups = df.index.get_level_values(0).get_duplicates()\n",
    "    \n",
    "    print( str(len(dups)) + ' Indexes were found to be duplicates')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Indexes were found to be duplicates\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read in the CSV file\n",
    "    df = pd.read_csv('input_data.csv', index_col=0)\n",
    "\n",
    "    # Get duplicate indexes\n",
    "    nodupes = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    nodupestest = nodupes.index.get_level_values(0).get_duplicates()\n",
    "\n",
    "    print(str(len(nodupestest)) + ' Indexes were found to be duplicates')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing NaNs\n",
    "This step involved removing NaNs from the data. NaNs could be introduced into the data if the user enters something incorrectly and the input isn't properly checked, or if there is no way for a user to answer a specific question so it is left blank. NaNs could be prevented by checking all input to make sure that is valid, in some cases a default value may also be given if the user doesn't enter something.  \n",
    "In order to remove NaNs the pandas library was used again, the dropna function allows NaNs to be removed from a dataset, in this instance a subset is provided as only columns 'q2' and 'q4' are being worked on in the weighting functions.  \n",
    "The print statements below show the columns that contain NaNs before and after the pandas function has been applied. The data now has no duplicate indexes, and columns 'q2' and 'q4' contain no NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without nulls being removed:  Index(['q2', 'q4'], dtype='object')\n",
      "With nulls being removed:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Read in the CSV file\n",
    "    df = pd.read_csv('input_data.csv', index_col=0)\n",
    "    \n",
    "    # Get duplicate indexes\n",
    "    nodupes = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Remove NaNs from dataset\n",
    "    nonulls = nodupes.dropna(subset=['q2', 'q4'])\n",
    "\n",
    "    print(\"Without nulls being removed:  \" + str(df.columns[df.isnull().any()]))\n",
    "    print(\"With nulls being removed:  \" + str(nonulls.columns[nonulls.isnull().any()]))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merging With New Data\n",
    "The final step involved merging two files together using the respondent number as an index. This was accomplished by performing a left join on the first file with the new file to be added. The left join kept only data that matched between the index from the original data and the index on the new data. In this case, a new column was added to the original data called q3 and every time the new data had an entry that matched an existing respondent number; the q3 data for that index was added.  \n",
    "There are other ways that data can be merged when dealing with two datasets. There are many joins that can be used, for example a right join would perform a similar operation to the left join but only keeping data matching the index on the right. An inner join could also be used to find an intersection between datasets, and an outer join could be used to include all data with a match from either dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read in input file\n",
    "    df = pd.read_csv('input_data.csv', index_col=0)\n",
    "\n",
    "    # Remove duplicate indexes, keep the first instance\n",
    "    nodupes = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    # Remove NaNs from dataset\n",
    "    nonulls = nodupes.dropna(subset=['q2', 'q4'])\n",
    "\n",
    "    # Read in q3 values\n",
    "    df_q3 = pd.read_csv('q3_column.csv', index_col=0)\n",
    "\n",
    "    # Merge q3 values with rest of dataframe\n",
    "    finaldf = nonulls.join(df_q3, how='left')\n",
    "    \n",
    "    # Write out cleaned csv file\n",
    "    finaldf.to_csv('cleaned.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Weighting Function Bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I could not complete this section. After attempting to run the program a number of times I always encountered runtime errors related to a number of indexes. I attempted to search for possible solutions for this but did not want to change much of the code as it may have broken other sections. I'm not sure if this was due to the setup on my personal computer.  \n",
    "Without being able to successfully run the program I can see that the count variable is not used within the weighting function. I would estimate that this could be used in a way to work out a ratio between the actual number of respondents and the universe size, and then assign a weight as used in the example to even them out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
